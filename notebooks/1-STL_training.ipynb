{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the 2L-SPC on STL-10 database\n",
    "https://arxiv.org/abs/2002.00892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str((Path(\"..\").resolve().absolute())))\n",
    "\n",
    "from  SPC_2L.DataTools import DataBase\n",
    "from SPC_2L.Network import LayerPC, Network\n",
    "from SPC_2L.Coding import ML_Lasso,ML_FISTA\n",
    "from SPC_2L.DataTools import DataBase, gaussian_kernel\n",
    "from SPC_2L.Monitor import Monitor\n",
    "from SPC_2L.Optimizers import mySGD, myAdam\n",
    "import torch.nn.functional as f\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "import tensorboardX\n",
    "from SPC_2L.DataTools import LCN, whitening, z_score, mask, to_device, norm\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import pickle\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torchvision.datasets import STL10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools, parameters and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (96) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m dataset \u001b[39m=\u001b[39m STL10(data_path, transform\u001b[39m=\u001b[39mtransform, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m DataBase \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m DataBase:\n\u001b[1;32m     15\u001b[0m     imshow(make_grid(batch[\u001b[39m0\u001b[39m]))\n\u001b[1;32m     16\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torchvision/datasets/stl10.py:121\u001b[0m, in \u001b[0;36mSTL10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    118\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(np\u001b[39m.\u001b[39mtranspose(img, (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)))\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Projects/SPC_2L/SPC_2L/DataTools.py:339\u001b[0m, in \u001b[0;36mmask.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (96) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "## Database \n",
    "data_path = '../data/STL/stl10_binary/'\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                    #whitening((96,96),f_0=0.5),\n",
    "                    Resize((96,96)),\n",
    "                    LCN(kernel_size=9,sigma=0.5,rgb=True),\n",
    "                    z_score(),\n",
    "                    mask((96,96))])\n",
    "\n",
    "dataset = STL10(data_path, transform=transform, download=True, split='train')\n",
    "\n",
    "DataBase = DataLoader(dataset, batch_size=20, shuffle=True, drop_last=True)\n",
    "for batch in DataBase:\n",
    "    imshow(make_grid(batch[0]))\n",
    "    break\n",
    "\n",
    "## Gaussian masks for the dictionaries\n",
    "mask_g = [gaussian_kernel((64,3,8,8), sigma=30), gaussian_kernel((128,64,8,8), sigma=30)]\n",
    "\n",
    "## Setting parameters\n",
    "l_r = [1e-4,5e-3]#### dictionaries learning rate [Layer1, Layer2]\n",
    "l_rv = [1e-3,1e-3]#### normalizer learning rate [Layer1, Layer2]\n",
    "l = [0.4,1.6]#### Sparsity parameters [Layer1, Layer2]\n",
    "b=1 #### Feedback strength parameter. b=0 --> Hila, b=1 --> 2L-SPC\n",
    "v_i=[10,10] #### Initial normalizer value [Layer1, Layer2]\n",
    "nb_epoch = 100 #### number of training epochs\n",
    "\n",
    "Use_tb = True #### Use to activate tensorboard monitoring\n",
    "save = False #### Use to run the entire simulation : TAKE HOURS. Use False to load previous simulation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and saving the network (b=0 for Hi-La, b=1 for 2L-SPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK STRUCTURE : \n",
      " Input : (20, 3, 96, 96)\n",
      " Layer 1 : [20, 64, 45, 45]\n",
      " Layer 2 : [20, 128, 38, 38]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Definition of the layers, network and sparse coding algorithm\n",
    "layer = [LayerPC((64, 3, 8, 8), stride=2, b=b, v=v_i[0], v_size=64 ,out_pad=0),\n",
    "        LayerPC((128, 64, 8, 8), stride=1, b=b, v=v_i[1], v_size=128 ,out_pad=0)]\n",
    "\n",
    "Net = Network(layer, input_size=(20, 3, 96,96))\n",
    "Loss = ML_Lasso(Net, [l[0],l[1]])\n",
    "Pursuit = ML_FISTA(Net, Loss, max_iter=1000, th=1e-4, mode='eigen')\n",
    "\n",
    "## Optimizer initialization\n",
    "opt_dico = [None] * (Net.nb_layers + 1)\n",
    "for i in range(0, Net.nb_layers):\n",
    "    opt_dico[i] = mySGD([{'params': Net.layers[i].dico}], lr=l_r[i], momentum=0.9, normalize=True)\n",
    "\n",
    "opt_v = [myAdam([{'params': Net.layers[i].v}], lr=l_rv[i], normalize=False) \\\n",
    "    for i in range(Net.nb_layers)]\n",
    "\n",
    "\n",
    "L = [None] * (Net.nb_layers)\n",
    "L_v = [None] * (Net.nb_layers)\n",
    "reco = [None] * (Net.nb_layers)\n",
    "\n",
    "model_name = 'STL_[{0},{1}]_b={2}'.format(l[0],l[1],b)\n",
    "path = 'Savings/STL/' + model_name +'.pkl'\n",
    "if Use_tb : \n",
    "    nrows = [8,8,8,8,8,8,8]\n",
    "    writer = SummaryWriter('Savings/Log/' + model_name)\n",
    "    M = Monitor(Net, writer, n_row=nrows)\n",
    "\n",
    "k=0\n",
    "\n",
    "l2_loss = torch.zeros(2,nb_epoch*len(DataBase))\n",
    "l1_loss = torch.zeros(2,nb_epoch*len(DataBase))\n",
    "if save == True : \n",
    "    for e in range(nb_epoch):\n",
    "        for idx_batch, data in enumerate(DataBase):\n",
    "\n",
    "            batch = data[0].to(discover_device())\n",
    "            gamma, it, Loss_G, delta = Pursuit.coding(batch)\n",
    "\n",
    "\n",
    "            for i in range(Net.nb_layers):\n",
    "                Net.layers[i].dico.requires_grad = True\n",
    "                L[i] = Loss.F(batch, gamma, i, do_feedback=False).div(batch.size()[0])  ## Unsupervised\n",
    "                L[i].backward()\n",
    "                Net.layers[i].dico.requires_grad = False\n",
    "                opt_dico[i].step()\n",
    "                opt_dico[i].zero_grad()\n",
    "\n",
    "                ##Mask\n",
    "                Net.layers[i].dico*=mask_g[i]\n",
    "                Net.layers[i].dico/=norm(Net.layers[i].dico)\n",
    "                \n",
    "                l2_loss[i,k]= L[i].detach() \n",
    "                l1_loss[i,k] =  gamma[i].detach().sum().div(gamma[i].size(0))\n",
    "                \n",
    "\n",
    "            for i in range(Net.nb_layers):\n",
    "                Net.layers[i].v.requires_grad = True  # turn_on(i)\n",
    "                L_v[i] = Loss.F_v(batch, gamma, i).div(batch.size()[0])\n",
    "                L_v[i].backward()\n",
    "                Net.layers[i].v.requires_grad = False  # turn_off(i)\n",
    "                opt_v[i].step()  \n",
    "                opt_v[i].zero_grad()\n",
    "                \n",
    "            if Use_tb:\n",
    "                if (k%10) == 0:\n",
    "                    writer.add_scalar('FISTA_iterations', it, k)\n",
    "                    M.MonitorGamma(gamma, k, option=['NNZ', '%', 'Sum', 'V'])\n",
    "                    M.MonitorList(L, 'Loss_Dico', k)\n",
    "                    M.MonitorList(L_v, 'Loss_v', k)\n",
    "                    M.MonitorDicoBP(k)\n",
    "                    M.ComputeHisto(gamma)\n",
    "\n",
    "                if (k%100) == 0:\n",
    "                    reco = [None] * (Net.nb_layers)\n",
    "                    for i in range(Net.nb_layers-1,-1,-1):\n",
    "                        reco[i] = gamma[i]\n",
    "                        for j in range(i, -1, -1):\n",
    "                            reco[i] = Net.layers[j].backward(reco[i])\n",
    "                        reco_image = make_grid(reco[i],normalize=True,pad_value=1)\n",
    "                        writer.add_image('Reco/L{0}'.format(i),reco_image,k)\n",
    "\n",
    "            k += 1\n",
    "\n",
    "    output_exp = {'Net': Net,\n",
    "            'Loss': Loss,\n",
    "            'Pursuit': Pursuit,\n",
    "            'l2_loss': l2_loss,\n",
    "            'l1_loss': l1_loss    \n",
    "                 }\n",
    "    path = 'Savings/STL/' + model_name +'.pkl'\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(output_exp, file, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "else :        \n",
    "    with open(path, 'rb') as file:\n",
    "        output_exp = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
