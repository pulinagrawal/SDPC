{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the 2L-SPC on CFD database\n",
    "https://arxiv.org/abs/2002.00892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pja5407/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str((Path(\"..\").resolve().absolute())))\n",
    "\n",
    "from  SPC_2L.DataTools import DataBase\n",
    "from SPC_2L.Network import LayerPC, Network\n",
    "from SPC_2L.Coding import ML_Lasso,ML_FISTA\n",
    "from SPC_2L.DataTools import DataBase, gaussian_kernel\n",
    "from SPC_2L.Monitor import Monitor\n",
    "from SPC_2L.Optimizers import mySGD, myAdam\n",
    "import torch.nn.functional as f\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "import tensorboardX\n",
    "from SPC_2L.DataTools import LCN, whitening, z_score, mask, to_cuda, norm\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import pickle\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools, parameters and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../DataSet/CF_DB_training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m      7\u001b[0m whitening_params\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mf_0\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0.5\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m2\u001b[39m} \u001b[39m# Whitening parameters\u001b[39;00m\n\u001b[1;32m      9\u001b[0m Data_load_param \u001b[39m=\u001b[39m { \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m10\u001b[39m,\n\u001b[1;32m     10\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mdo_LCN\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mLCN_params\u001b[39m\u001b[39m'\u001b[39m: LCN_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mreturn_idx\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                   }\n\u001b[0;32m---> 20\u001b[0m Facedata \u001b[39m=\u001b[39m DataBase(\u001b[39m'\u001b[39;49m\u001b[39mfrom_ImageFolder\u001b[39;49m\u001b[39m'\u001b[39;49m, data_path, img_size\u001b[39m=\u001b[39;49m(\u001b[39m100\u001b[39;49m,\u001b[39m124\u001b[39;49m),reshaped_size\u001b[39m=\u001b[39;49m(\u001b[39m120\u001b[39;49m,\u001b[39m171\u001b[39;49m),\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mData_load_param, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     22\u001b[0m \u001b[39m## Setting parameters\u001b[39;00m\n\u001b[1;32m     23\u001b[0m l_r \u001b[39m=\u001b[39m [\u001b[39m1e-4\u001b[39m,\u001b[39m5e-3\u001b[39m]\u001b[39m#### dictionaries learning rate [Layer1, Layer2]\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/SPC_2L/SPC_2L/DataTools.py:78\u001b[0m, in \u001b[0;36mDataBase.__init__\u001b[0;34m(self, name, path, batch_size, shuffle, reshaped_size, img_size, gray_scale, do_mask, mask_params, do_LCN, LCN_params, do_whitening, whitening_params, do_z_score, num_workers, path_target, normalize, return_idx)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfrom_ImageFolder\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     77\u001b[0m     transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(list_of_transforms)\n\u001b[0;32m---> 78\u001b[0m     data_set \u001b[39m=\u001b[39m MyImageLoader(\n\u001b[1;32m     79\u001b[0m         root\u001b[39m=\u001b[39;49mpath, transform\u001b[39m=\u001b[39;49mtransform, retun_idx\u001b[39m=\u001b[39;49mreturn_idx)\n\u001b[1;32m     80\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCIFAR10_tr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     81\u001b[0m     \u001b[39mif\u001b[39;00m normalize \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/SPC_2L/SPC_2L/DataTools.py:346\u001b[0m, in \u001b[0;36mMyImageLoader.__init__\u001b[0;34m(self, root, transform, target_transform, loader, retun_idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, target_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    345\u001b[0m              loader\u001b[39m=\u001b[39mdefault_loader, retun_idx\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 346\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m find_classes(root)\n\u001b[1;32m    347\u001b[0m     IMG_EXTENSIONS \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.jpeg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    348\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39m.ppm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.bmp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.pgm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.tif\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    350\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../DataSet/CF_DB_training'"
     ]
    }
   ],
   "source": [
    "data_path = '../DataSet/CF_DB_training'\n",
    "\n",
    "LCN_params = {'kernel_size':11,'sigma':0.5, 'rgb':True} # Local contrast normalization parameters\n",
    "\n",
    "mask_params={'n': 10} # mask parameters\n",
    "\n",
    "whitening_params={'f_0':0.5,'n':2} # Whitening parameters\n",
    "\n",
    "Data_load_param = { 'batch_size': 10,\n",
    "                    'do_LCN': True,\n",
    "                    'LCN_params': LCN_params,\n",
    "                    'do_mask': True,\n",
    "                    'mask_params': mask_params,\n",
    "                    'do_whitening': True,\n",
    "                    'whitening_params': whitening_params,\n",
    "                    'do_z_score': True,\n",
    "                    'return_idx': False\n",
    "                  }\n",
    "\n",
    "Facedata = DataBase('from_ImageFolder', data_path, img_size=(100,124),reshaped_size=(120,171),**Data_load_param, shuffle=True)\n",
    "    \n",
    "## Setting parameters\n",
    "l_r = [1e-4,5e-3]#### dictionaries learning rate [Layer1, Layer2]\n",
    "l_rv = [1e-3,1e-3]#### normalizer learning rate [Layer1, Layer2]\n",
    "l = [0.5,1.8]#### Sparsity parameters [Layer1, Layer2]\n",
    "b=0#### Feedback strength parameter. b=0 --> Hila, b=1 --> 2L-SPC\n",
    "v_i=[6,6] #### Initial normalizer value [Layer1, Layer2]\n",
    "nb_epoch = 375 #### number of training epochs\n",
    "\n",
    "Use_tb = True #### Use to activate tensorboard monitoring\n",
    "save = True #### Use to run the entire simulation : TAKE HOURS. Use False to load previous simulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and saving the network (b=0 for Hi-La, b=1 for 2L-SPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## Definition of the layers, network and sparse coding algorithm\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m layer \u001b[39m=\u001b[39m [LayerPC((\u001b[39m64\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m9\u001b[39m), stride\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, b\u001b[39m=\u001b[39mb, v\u001b[39m=\u001b[39mv_i[\u001b[39m0\u001b[39m], v_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m ,out_pad\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m      3\u001b[0m         LayerPC((\u001b[39m128\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m9\u001b[39m), stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, b\u001b[39m=\u001b[39mb, v\u001b[39m=\u001b[39mv_i[\u001b[39m1\u001b[39m], v_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m ,out_pad\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)]\n\u001b[1;32m      5\u001b[0m Net \u001b[39m=\u001b[39m Network(layer, input_size\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m120\u001b[39m, \u001b[39m171\u001b[39m))\n\u001b[1;32m      6\u001b[0m Loss \u001b[39m=\u001b[39m ML_Lasso(Net, [l[\u001b[39m0\u001b[39m],l[\u001b[39m1\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "## Definition of the layers, network and sparse coding algorithm\n",
    "layer = [LayerPC((64, 3, 9, 9), stride=3, b=b, v=v_i[0], v_size=64 ,out_pad=0),\n",
    "        LayerPC((128, 64, 9, 9), stride=1, b=b, v=v_i[1], v_size=128 ,out_pad=0)]\n",
    "\n",
    "Net = Network(layer, input_size=(20, 3, 120, 171))\n",
    "Loss = ML_Lasso(Net, [l[0],l[1]])\n",
    "Pursuit = ML_FISTA(Net, Loss, max_iter=1000, th=5e-3, mode='eigen')\n",
    "\n",
    "## Optimizer initialization\n",
    "opt_dico = [None] * (Net.nb_layers + 1)\n",
    "for i in range(0, Net.nb_layers):\n",
    "    opt_dico[i] = mySGD([{'params': Net.layers[i].dico}], lr=l_r[i], momentum=0.9, normalize=True)\n",
    "\n",
    "opt_v = [myAdam([{'params': Net.layers[i].v}], lr=l_rv[i], normalize=False) \\\n",
    "         for i in range(Net.nb_layers)]\n",
    "\n",
    "L = [None] * (Net.nb_layers)\n",
    "L_v = [None] * (Net.nb_layers)\n",
    "reco = [None] * (Net.nb_layers)\n",
    "\n",
    "model_name = 'CFD_[{0},{1}]_b={2}'.format(l[0],l[1],b)\n",
    "path = 'Savings/CFD/' + model_name +'.pkl'\n",
    "\n",
    "if Use_tb : \n",
    "    nrows = [8,8,8,8,8,8,8]\n",
    "    writer = SummaryWriter('Savings/Log/' + model_name)\n",
    "    M = Monitor(Net, writer, n_row=nrows)\n",
    "\n",
    "k=0\n",
    "\n",
    "l2_loss = torch.zeros(2,nb_epoch*Facedata.size[0]*Facedata.size[1])\n",
    "l1_loss = torch.zeros(2,nb_epoch*Facedata.size[0]*Facedata.size[1])\n",
    "\n",
    "if save == True:\n",
    "    for e in range(nb_epoch):\n",
    "        for idx_batch, data in enumerate(Facedata.data):\n",
    "\n",
    "            batch = data[0].cuda()\n",
    "            gamma, it, Loss_G, delta = Pursuit.coding(batch)\n",
    "\n",
    "            for i in range(Net.nb_layers):\n",
    "                Net.layers[i].dico.requires_grad = True\n",
    "                L[i] = Loss.F(batch, gamma, i, do_feedback=False).div(batch.size()[0])  ## Unsupervised\n",
    "                L[i].backward()\n",
    "                Net.layers[i].dico.requires_grad = False\n",
    "                opt_dico[i].step()\n",
    "                opt_dico[i].zero_grad()\n",
    "                \n",
    "                l2_loss[i,k]= L[i].detach() \n",
    "                l1_loss[i,k] =  gamma[i].detach().sum().div(gamma[i].size(0))\n",
    "                \n",
    "            for i in range(Net.nb_layers):\n",
    "                Net.layers[i].v.requires_grad = True  # turn_on(i)\n",
    "                L_v[i] = Loss.F_v(batch, gamma, i).div(batch.size()[0])\n",
    "                L_v[i].backward()\n",
    "                Net.layers[i].v.requires_grad = False  # turn_off(i)\n",
    "                opt_v[i].step()  \n",
    "                opt_v[i].zero_grad()\n",
    "                \n",
    "            if Use_tb:\n",
    "                if (k%10) == 0:\n",
    "                    writer.add_scalar('FISTA_iterations', it, k)\n",
    "                    M.MonitorGamma(gamma, k, option=['NNZ', '%', 'Sum', 'V'])\n",
    "                    M.MonitorList(L, 'Loss_Dico', k)\n",
    "                    M.MonitorList(L_v, 'Loss_v', k)\n",
    "                    M.MonitorDicoBP(k)\n",
    "                    M.ComputeHisto(gamma)\n",
    "\n",
    "                if (k%100) == 0:\n",
    "                    reco = [None] * (Net.nb_layers)\n",
    "                    for i in range(Net.nb_layers-1,-1,-1):\n",
    "                        reco[i] = gamma[i]\n",
    "                        for j in range(i, -1, -1):\n",
    "                            reco[i] = Net.layers[j].backward(reco[i])\n",
    "                        reco_image = make_grid(reco[i],normalize=True,pad_value=1)\n",
    "                        writer.add_image('Reco/L{0}'.format(i),reco_image,k)\n",
    "\n",
    "            k += 1\n",
    "\n",
    "    output_exp = {'Net': Net,\n",
    "            'Loss': Loss,\n",
    "            'Pursuit': Pursuit,\n",
    "            'l2_loss': l2_loss,\n",
    "            'l1_loss': l1_loss    \n",
    "                 }\n",
    "    path = 'Savings/CFD/' + model_name +'.pkl'\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(output_exp, file, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "else :        \n",
    "    with open(path, 'rb') as file:\n",
    "        output_exp = pickle.load(file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
